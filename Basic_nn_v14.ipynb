{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51da821",
   "metadata": {
    "papermill": {
     "duration": 0.011902,
     "end_time": "2023-02-22T15:17:47.844850",
     "exception": false,
     "start_time": "2023-02-22T15:17:47.832948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Link to another tutorial site that I was using to figure this out:\n",
    "https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a026f150",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-22T15:17:47.861146Z",
     "iopub.status.busy": "2023-02-22T15:17:47.860340Z",
     "iopub.status.idle": "2023-02-22T15:17:56.763247Z",
     "shell.execute_reply": "2023-02-22T15:17:56.761649Z"
    },
    "papermill": {
     "duration": 8.914147,
     "end_time": "2023-02-22T15:17:56.766009",
     "exception": false,
     "start_time": "2023-02-22T15:17:47.851862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/widsdatathon2023/train_data.csv\n",
      "/kaggle/input/widsdatathon2023/test_data.csv\n",
      "/kaggle/input/widsdatathon2023/sample_solution.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing #Convert categorical data to neumeric values\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd63cfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:17:56.781962Z",
     "iopub.status.busy": "2023-02-22T15:17:56.781089Z",
     "iopub.status.idle": "2023-02-22T15:17:56.787025Z",
     "shell.execute_reply": "2023-02-22T15:17:56.785940Z"
    },
    "papermill": {
     "duration": 0.016375,
     "end_time": "2023-02-22T15:17:56.789317",
     "exception": false,
     "start_time": "2023-02-22T15:17:56.772942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keep_columns=['lat','month','contest-tmp2m-14d__tmp2m',\n",
    "              'climateregions__climateregion','lon']\n",
    "X_columns=[['lat','month',\n",
    "              'climateregions__climateregion','lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55d2993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:17:56.805154Z",
     "iopub.status.busy": "2023-02-22T15:17:56.804219Z",
     "iopub.status.idle": "2023-02-22T15:17:56.810018Z",
     "shell.execute_reply": "2023-02-22T15:17:56.808843Z"
    },
    "papermill": {
     "duration": 0.016182,
     "end_time": "2023-02-22T15:17:56.812435",
     "exception": false,
     "start_time": "2023-02-22T15:17:56.796253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seperate_monthly(df):\n",
    "    df[['month','day','year']]=df.startdate.str.split('/',expand=True)\n",
    "    df=df.drop('day', axis=1)\n",
    "    df=df.drop('startdate',axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de3422b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:17:56.828264Z",
     "iopub.status.busy": "2023-02-22T15:17:56.827823Z",
     "iopub.status.idle": "2023-02-22T15:17:56.833704Z",
     "shell.execute_reply": "2023-02-22T15:17:56.832591Z"
    },
    "papermill": {
     "duration": 0.016353,
     "end_time": "2023-02-22T15:17:56.835935",
     "exception": false,
     "start_time": "2023-02-22T15:17:56.819582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eliminate_columns(df):\n",
    "    for col in df.columns:\n",
    "        if col in keep_columns:\n",
    "            print(col)\n",
    "        else: \n",
    "            df=df.drop(col, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a4bcff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:17:56.852255Z",
     "iopub.status.busy": "2023-02-22T15:17:56.851298Z",
     "iopub.status.idle": "2023-02-22T15:17:56.857121Z",
     "shell.execute_reply": "2023-02-22T15:17:56.856321Z"
    },
    "papermill": {
     "duration": 0.016346,
     "end_time": "2023-02-22T15:17:56.859257",
     "exception": false,
     "start_time": "2023-02-22T15:17:56.842911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#need to come up with a different way to do this, because it is not working\n",
    "def seperate_y(df):\n",
    "    y_df=df['contest-tmp2m-14d__tmp2m']\n",
    "    X_df=df.drop('contest-tmp2m-14d__tmp2m',axis=1)\n",
    "    return y_df,X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b214d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:17:56.875085Z",
     "iopub.status.busy": "2023-02-22T15:17:56.874425Z",
     "iopub.status.idle": "2023-02-22T15:17:56.880055Z",
     "shell.execute_reply": "2023-02-22T15:17:56.878874Z"
    },
    "papermill": {
     "duration": 0.015942,
     "end_time": "2023-02-22T15:17:56.882183",
     "exception": false,
     "start_time": "2023-02-22T15:17:56.866241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normanlize_data(df,train_df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column]  /  train_df[column].abs().max()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a9bc78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:17:56.898141Z",
     "iopub.status.busy": "2023-02-22T15:17:56.897245Z",
     "iopub.status.idle": "2023-02-22T15:18:23.855812Z",
     "shell.execute_reply": "2023-02-22T15:18:23.854293Z"
    },
    "papermill": {
     "duration": 26.969472,
     "end_time": "2023-02-22T15:18:23.858550",
     "exception": false,
     "start_time": "2023-02-22T15:17:56.889078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>startdate</th>\n",
       "      <th>contest-pevpr-sfc-gauss-14d__pevpr</th>\n",
       "      <th>nmme0-tmp2m-34w__cancm30</th>\n",
       "      <th>nmme0-tmp2m-34w__cancm40</th>\n",
       "      <th>nmme0-tmp2m-34w__ccsm30</th>\n",
       "      <th>nmme0-tmp2m-34w__ccsm40</th>\n",
       "      <th>nmme0-tmp2m-34w__cfsv20</th>\n",
       "      <th>...</th>\n",
       "      <th>wind-vwnd-925-2010-11</th>\n",
       "      <th>wind-vwnd-925-2010-12</th>\n",
       "      <th>wind-vwnd-925-2010-13</th>\n",
       "      <th>wind-vwnd-925-2010-14</th>\n",
       "      <th>wind-vwnd-925-2010-15</th>\n",
       "      <th>wind-vwnd-925-2010-16</th>\n",
       "      <th>wind-vwnd-925-2010-17</th>\n",
       "      <th>wind-vwnd-925-2010-18</th>\n",
       "      <th>wind-vwnd-925-2010-19</th>\n",
       "      <th>wind-vwnd-925-2010-20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9/1/14</td>\n",
       "      <td>237.00</td>\n",
       "      <td>29.02</td>\n",
       "      <td>31.64</td>\n",
       "      <td>29.57</td>\n",
       "      <td>30.73</td>\n",
       "      <td>29.71</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.68</td>\n",
       "      <td>-37.21</td>\n",
       "      <td>8.32</td>\n",
       "      <td>9.56</td>\n",
       "      <td>-2.03</td>\n",
       "      <td>48.13</td>\n",
       "      <td>28.09</td>\n",
       "      <td>-13.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9/2/14</td>\n",
       "      <td>228.90</td>\n",
       "      <td>29.02</td>\n",
       "      <td>31.64</td>\n",
       "      <td>29.57</td>\n",
       "      <td>30.73</td>\n",
       "      <td>29.71</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.13</td>\n",
       "      <td>-36.57</td>\n",
       "      <td>8.77</td>\n",
       "      <td>21.17</td>\n",
       "      <td>4.44</td>\n",
       "      <td>48.60</td>\n",
       "      <td>27.41</td>\n",
       "      <td>-23.77</td>\n",
       "      <td>15.44</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9/3/14</td>\n",
       "      <td>220.69</td>\n",
       "      <td>29.02</td>\n",
       "      <td>31.64</td>\n",
       "      <td>29.57</td>\n",
       "      <td>30.73</td>\n",
       "      <td>29.71</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.72</td>\n",
       "      <td>-34.16</td>\n",
       "      <td>6.99</td>\n",
       "      <td>32.16</td>\n",
       "      <td>5.01</td>\n",
       "      <td>48.53</td>\n",
       "      <td>19.21</td>\n",
       "      <td>-33.16</td>\n",
       "      <td>15.11</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9/4/14</td>\n",
       "      <td>225.28</td>\n",
       "      <td>29.02</td>\n",
       "      <td>31.64</td>\n",
       "      <td>29.57</td>\n",
       "      <td>30.73</td>\n",
       "      <td>29.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-31.04</td>\n",
       "      <td>6.17</td>\n",
       "      <td>39.66</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>50.59</td>\n",
       "      <td>8.29</td>\n",
       "      <td>-37.22</td>\n",
       "      <td>18.24</td>\n",
       "      <td>9.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9/5/14</td>\n",
       "      <td>237.24</td>\n",
       "      <td>29.02</td>\n",
       "      <td>31.64</td>\n",
       "      <td>29.57</td>\n",
       "      <td>30.73</td>\n",
       "      <td>29.71</td>\n",
       "      <td>...</td>\n",
       "      <td>9.83</td>\n",
       "      <td>-31.80</td>\n",
       "      <td>7.47</td>\n",
       "      <td>38.62</td>\n",
       "      <td>-5.21</td>\n",
       "      <td>54.73</td>\n",
       "      <td>-2.58</td>\n",
       "      <td>-42.30</td>\n",
       "      <td>21.91</td>\n",
       "      <td>10.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375729</th>\n",
       "      <td>375729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>8/27/16</td>\n",
       "      <td>312.05</td>\n",
       "      <td>23.13</td>\n",
       "      <td>27.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>24.43</td>\n",
       "      <td>18.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.64</td>\n",
       "      <td>-75.68</td>\n",
       "      <td>-3.09</td>\n",
       "      <td>6.93</td>\n",
       "      <td>-16.69</td>\n",
       "      <td>16.98</td>\n",
       "      <td>-13.85</td>\n",
       "      <td>50.25</td>\n",
       "      <td>-31.33</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375730</th>\n",
       "      <td>375730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>8/28/16</td>\n",
       "      <td>305.82</td>\n",
       "      <td>23.13</td>\n",
       "      <td>27.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>24.43</td>\n",
       "      <td>18.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.59</td>\n",
       "      <td>-76.42</td>\n",
       "      <td>-13.55</td>\n",
       "      <td>13.36</td>\n",
       "      <td>-15.96</td>\n",
       "      <td>20.45</td>\n",
       "      <td>-16.36</td>\n",
       "      <td>51.65</td>\n",
       "      <td>-30.73</td>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375731</th>\n",
       "      <td>375731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>8/29/16</td>\n",
       "      <td>311.62</td>\n",
       "      <td>23.13</td>\n",
       "      <td>27.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>24.43</td>\n",
       "      <td>18.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-70.65</td>\n",
       "      <td>-23.93</td>\n",
       "      <td>22.62</td>\n",
       "      <td>-16.71</td>\n",
       "      <td>20.28</td>\n",
       "      <td>-15.48</td>\n",
       "      <td>48.58</td>\n",
       "      <td>-18.74</td>\n",
       "      <td>9.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375732</th>\n",
       "      <td>375732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>8/30/16</td>\n",
       "      <td>304.54</td>\n",
       "      <td>23.13</td>\n",
       "      <td>27.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>24.43</td>\n",
       "      <td>18.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.16</td>\n",
       "      <td>-57.67</td>\n",
       "      <td>-33.55</td>\n",
       "      <td>32.06</td>\n",
       "      <td>-16.07</td>\n",
       "      <td>16.60</td>\n",
       "      <td>-20.61</td>\n",
       "      <td>39.23</td>\n",
       "      <td>-16.26</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375733</th>\n",
       "      <td>375733</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>8/31/16</td>\n",
       "      <td>295.29</td>\n",
       "      <td>23.13</td>\n",
       "      <td>27.20</td>\n",
       "      <td>20.25</td>\n",
       "      <td>24.43</td>\n",
       "      <td>18.35</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.36</td>\n",
       "      <td>-44.67</td>\n",
       "      <td>-32.46</td>\n",
       "      <td>36.25</td>\n",
       "      <td>-12.72</td>\n",
       "      <td>15.98</td>\n",
       "      <td>-22.56</td>\n",
       "      <td>32.53</td>\n",
       "      <td>-21.89</td>\n",
       "      <td>-1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352604 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  lat       lon startdate  contest-pevpr-sfc-gauss-14d__pevpr  \\\n",
       "0            0  0.0  0.833333    9/1/14                              237.00   \n",
       "1            1  0.0  0.833333    9/2/14                              228.90   \n",
       "2            2  0.0  0.833333    9/3/14                              220.69   \n",
       "3            3  0.0  0.833333    9/4/14                              225.28   \n",
       "4            4  0.0  0.833333    9/5/14                              237.24   \n",
       "...        ...  ...       ...       ...                                 ...   \n",
       "375729  375729  1.0  0.866667   8/27/16                              312.05   \n",
       "375730  375730  1.0  0.866667   8/28/16                              305.82   \n",
       "375731  375731  1.0  0.866667   8/29/16                              311.62   \n",
       "375732  375732  1.0  0.866667   8/30/16                              304.54   \n",
       "375733  375733  1.0  0.866667   8/31/16                              295.29   \n",
       "\n",
       "        nmme0-tmp2m-34w__cancm30  nmme0-tmp2m-34w__cancm40  \\\n",
       "0                          29.02                     31.64   \n",
       "1                          29.02                     31.64   \n",
       "2                          29.02                     31.64   \n",
       "3                          29.02                     31.64   \n",
       "4                          29.02                     31.64   \n",
       "...                          ...                       ...   \n",
       "375729                     23.13                     27.20   \n",
       "375730                     23.13                     27.20   \n",
       "375731                     23.13                     27.20   \n",
       "375732                     23.13                     27.20   \n",
       "375733                     23.13                     27.20   \n",
       "\n",
       "        nmme0-tmp2m-34w__ccsm30  nmme0-tmp2m-34w__ccsm40  \\\n",
       "0                         29.57                    30.73   \n",
       "1                         29.57                    30.73   \n",
       "2                         29.57                    30.73   \n",
       "3                         29.57                    30.73   \n",
       "4                         29.57                    30.73   \n",
       "...                         ...                      ...   \n",
       "375729                    20.25                    24.43   \n",
       "375730                    20.25                    24.43   \n",
       "375731                    20.25                    24.43   \n",
       "375732                    20.25                    24.43   \n",
       "375733                    20.25                    24.43   \n",
       "\n",
       "        nmme0-tmp2m-34w__cfsv20  ...  wind-vwnd-925-2010-11  \\\n",
       "0                         29.71  ...                 -27.68   \n",
       "1                         29.71  ...                 -21.13   \n",
       "2                         29.71  ...                 -10.72   \n",
       "3                         29.71  ...                   0.33   \n",
       "4                         29.71  ...                   9.83   \n",
       "...                         ...  ...                    ...   \n",
       "375729                    18.35  ...                 -15.64   \n",
       "375730                    18.35  ...                  -7.59   \n",
       "375731                    18.35  ...                  -6.25   \n",
       "375732                    18.35  ...                  -7.16   \n",
       "375733                    18.35  ...                 -12.36   \n",
       "\n",
       "        wind-vwnd-925-2010-12  wind-vwnd-925-2010-13  wind-vwnd-925-2010-14  \\\n",
       "0                      -37.21                   8.32                   9.56   \n",
       "1                      -36.57                   8.77                  21.17   \n",
       "2                      -34.16                   6.99                  32.16   \n",
       "3                      -31.04                   6.17                  39.66   \n",
       "4                      -31.80                   7.47                  38.62   \n",
       "...                       ...                    ...                    ...   \n",
       "375729                 -75.68                  -3.09                   6.93   \n",
       "375730                 -76.42                 -13.55                  13.36   \n",
       "375731                 -70.65                 -23.93                  22.62   \n",
       "375732                 -57.67                 -33.55                  32.06   \n",
       "375733                 -44.67                 -32.46                  36.25   \n",
       "\n",
       "        wind-vwnd-925-2010-15  wind-vwnd-925-2010-16  wind-vwnd-925-2010-17  \\\n",
       "0                       -2.03                  48.13                  28.09   \n",
       "1                        4.44                  48.60                  27.41   \n",
       "2                        5.01                  48.53                  19.21   \n",
       "3                       -1.41                  50.59                   8.29   \n",
       "4                       -5.21                  54.73                  -2.58   \n",
       "...                       ...                    ...                    ...   \n",
       "375729                 -16.69                  16.98                 -13.85   \n",
       "375730                 -15.96                  20.45                 -16.36   \n",
       "375731                 -16.71                  20.28                 -15.48   \n",
       "375732                 -16.07                  16.60                 -20.61   \n",
       "375733                 -12.72                  15.98                 -22.56   \n",
       "\n",
       "        wind-vwnd-925-2010-18  wind-vwnd-925-2010-19  wind-vwnd-925-2010-20  \n",
       "0                      -13.50                  11.90                   4.58  \n",
       "1                      -23.77                  15.44                   3.42  \n",
       "2                      -33.16                  15.11                   4.82  \n",
       "3                      -37.22                  18.24                   9.74  \n",
       "4                      -42.30                  21.91                  10.95  \n",
       "...                       ...                    ...                    ...  \n",
       "375729                  50.25                 -31.33                   0.77  \n",
       "375730                  51.65                 -30.73                  10.10  \n",
       "375731                  48.58                 -18.74                   9.28  \n",
       "375732                  39.23                 -16.26                  -0.22  \n",
       "375733                  32.53                 -21.89                  -1.20  \n",
       "\n",
       "[352604 rows x 246 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv('/kaggle/input/widsdatathon2023/train_data.csv')\n",
    "train_df=train_df.dropna(axis=0)\n",
    "test_df=pd.read_csv('/kaggle/input/widsdatathon2023/test_data.csv')\n",
    "test_df=test_df.dropna(axis=0)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cfeae78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:23.876029Z",
     "iopub.status.busy": "2023-02-22T15:18:23.875579Z",
     "iopub.status.idle": "2023-02-22T15:18:24.548580Z",
     "shell.execute_reply": "2023-02-22T15:18:24.547460Z"
    },
    "papermill": {
     "duration": 0.684781,
     "end_time": "2023-02-22T15:18:24.551357",
     "exception": false,
     "start_time": "2023-02-22T15:18:23.866576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Shuffeling the data\n",
    "train_df = train_df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a3ce19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:24.567753Z",
     "iopub.status.busy": "2023-02-22T15:18:24.567381Z",
     "iopub.status.idle": "2023-02-22T15:18:24.676085Z",
     "shell.execute_reply": "2023-02-22T15:18:24.675196Z"
    },
    "papermill": {
     "duration": 0.119928,
     "end_time": "2023-02-22T15:18:24.678699",
     "exception": false,
     "start_time": "2023-02-22T15:18:24.558771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "train_df['climateregions__climateregion']=le.fit_transform(train_df['climateregions__climateregion'])\n",
    "test_df['climateregions__climateregion']=le.fit_transform(test_df['climateregions__climateregion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a3a0ddc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:24.696314Z",
     "iopub.status.busy": "2023-02-22T15:18:24.695111Z",
     "iopub.status.idle": "2023-02-22T15:18:26.673990Z",
     "shell.execute_reply": "2023-02-22T15:18:26.672532Z"
    },
    "papermill": {
     "duration": 1.990127,
     "end_time": "2023-02-22T15:18:26.676502",
     "exception": false,
     "start_time": "2023-02-22T15:18:24.686375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set prep\n",
      "test set prep\n"
     ]
    }
   ],
   "source": [
    "print('training set prep')\n",
    "train_df=seperate_monthly(train_df)\n",
    "#train_df=eliminate_columns(train_df)\n",
    "print('test set prep')\n",
    "test_df=seperate_monthly(test_df)\n",
    "#test_df=eliminate_columns(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5464f8cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:26.692894Z",
     "iopub.status.busy": "2023-02-22T15:18:26.692537Z",
     "iopub.status.idle": "2023-02-22T15:18:26.833006Z",
     "shell.execute_reply": "2023-02-22T15:18:26.831826Z"
    },
    "papermill": {
     "duration": 0.151484,
     "end_time": "2023-02-22T15:18:26.835418",
     "exception": false,
     "start_time": "2023-02-22T15:18:26.683934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>contest-pevpr-sfc-gauss-14d__pevpr</th>\n",
       "      <th>nmme0-tmp2m-34w__cancm30</th>\n",
       "      <th>nmme0-tmp2m-34w__cancm40</th>\n",
       "      <th>nmme0-tmp2m-34w__ccsm30</th>\n",
       "      <th>nmme0-tmp2m-34w__ccsm40</th>\n",
       "      <th>nmme0-tmp2m-34w__cfsv20</th>\n",
       "      <th>nmme0-tmp2m-34w__gfdlflora0</th>\n",
       "      <th>...</th>\n",
       "      <th>wind-vwnd-925-2010-13</th>\n",
       "      <th>wind-vwnd-925-2010-14</th>\n",
       "      <th>wind-vwnd-925-2010-15</th>\n",
       "      <th>wind-vwnd-925-2010-16</th>\n",
       "      <th>wind-vwnd-925-2010-17</th>\n",
       "      <th>wind-vwnd-925-2010-18</th>\n",
       "      <th>wind-vwnd-925-2010-19</th>\n",
       "      <th>wind-vwnd-925-2010-20</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232387</th>\n",
       "      <td>232387</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>338.53</td>\n",
       "      <td>14.63</td>\n",
       "      <td>17.29</td>\n",
       "      <td>16.47</td>\n",
       "      <td>14.56</td>\n",
       "      <td>14.64</td>\n",
       "      <td>18.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.84</td>\n",
       "      <td>14.57</td>\n",
       "      <td>2.38</td>\n",
       "      <td>-27.81</td>\n",
       "      <td>-53.09</td>\n",
       "      <td>18.53</td>\n",
       "      <td>43.93</td>\n",
       "      <td>-16.79</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278778</th>\n",
       "      <td>278778</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>465.32</td>\n",
       "      <td>11.37</td>\n",
       "      <td>11.85</td>\n",
       "      <td>11.03</td>\n",
       "      <td>11.21</td>\n",
       "      <td>12.34</td>\n",
       "      <td>10.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.31</td>\n",
       "      <td>24.93</td>\n",
       "      <td>-11.19</td>\n",
       "      <td>-25.75</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>9.48</td>\n",
       "      <td>-14.57</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348195</th>\n",
       "      <td>348195</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>262.21</td>\n",
       "      <td>2.85</td>\n",
       "      <td>6.07</td>\n",
       "      <td>2.62</td>\n",
       "      <td>6.55</td>\n",
       "      <td>7.24</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.02</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-2.57</td>\n",
       "      <td>-26.51</td>\n",
       "      <td>47.62</td>\n",
       "      <td>-38.61</td>\n",
       "      <td>4.73</td>\n",
       "      <td>69.81</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341086</th>\n",
       "      <td>341086</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>17.29</td>\n",
       "      <td>4.78</td>\n",
       "      <td>7.90</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.81</td>\n",
       "      <td>5.42</td>\n",
       "      <td>6.31</td>\n",
       "      <td>...</td>\n",
       "      <td>6.40</td>\n",
       "      <td>47.12</td>\n",
       "      <td>-38.47</td>\n",
       "      <td>9.61</td>\n",
       "      <td>46.26</td>\n",
       "      <td>-35.05</td>\n",
       "      <td>-12.54</td>\n",
       "      <td>37.37</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245447</th>\n",
       "      <td>245447</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>57.03</td>\n",
       "      <td>-7.91</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-6.91</td>\n",
       "      <td>-6.72</td>\n",
       "      <td>-5.98</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.57</td>\n",
       "      <td>42.76</td>\n",
       "      <td>3.71</td>\n",
       "      <td>-37.34</td>\n",
       "      <td>-4.44</td>\n",
       "      <td>-9.71</td>\n",
       "      <td>50.98</td>\n",
       "      <td>5.56</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274683</th>\n",
       "      <td>274683</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>111.01</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>35.70</td>\n",
       "      <td>30.94</td>\n",
       "      <td>-24.58</td>\n",
       "      <td>10.69</td>\n",
       "      <td>3.29</td>\n",
       "      <td>28.62</td>\n",
       "      <td>10.27</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247787</th>\n",
       "      <td>247787</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>508.53</td>\n",
       "      <td>22.07</td>\n",
       "      <td>24.30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>20.49</td>\n",
       "      <td>18.54</td>\n",
       "      <td>19.37</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.03</td>\n",
       "      <td>33.65</td>\n",
       "      <td>-56.23</td>\n",
       "      <td>-34.12</td>\n",
       "      <td>19.45</td>\n",
       "      <td>74.22</td>\n",
       "      <td>-14.56</td>\n",
       "      <td>-24.92</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359644</th>\n",
       "      <td>359644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>315.28</td>\n",
       "      <td>15.15</td>\n",
       "      <td>17.45</td>\n",
       "      <td>12.96</td>\n",
       "      <td>15.20</td>\n",
       "      <td>14.46</td>\n",
       "      <td>14.68</td>\n",
       "      <td>...</td>\n",
       "      <td>6.68</td>\n",
       "      <td>7.30</td>\n",
       "      <td>-33.97</td>\n",
       "      <td>10.50</td>\n",
       "      <td>3.91</td>\n",
       "      <td>30.85</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-14.04</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77978</th>\n",
       "      <td>77978</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>56.95</td>\n",
       "      <td>2.04</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.04</td>\n",
       "      <td>4.61</td>\n",
       "      <td>3.09</td>\n",
       "      <td>4.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.85</td>\n",
       "      <td>20.75</td>\n",
       "      <td>9.01</td>\n",
       "      <td>-81.74</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-6.00</td>\n",
       "      <td>16.98</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59950</th>\n",
       "      <td>59950</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>313.57</td>\n",
       "      <td>27.62</td>\n",
       "      <td>29.09</td>\n",
       "      <td>28.63</td>\n",
       "      <td>25.41</td>\n",
       "      <td>22.49</td>\n",
       "      <td>25.27</td>\n",
       "      <td>...</td>\n",
       "      <td>45.85</td>\n",
       "      <td>34.57</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>62.43</td>\n",
       "      <td>-19.59</td>\n",
       "      <td>-45.81</td>\n",
       "      <td>46.65</td>\n",
       "      <td>8.39</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352604 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index       lat       lon  contest-pevpr-sfc-gauss-14d__pevpr  \\\n",
       "232387  232387  0.681818  0.733333                              338.53   \n",
       "278778  278778  0.818182  0.066667                              465.32   \n",
       "348195  348195  0.954545  0.466667                              262.21   \n",
       "341086  341086  0.954545  0.133333                               17.29   \n",
       "245447  245447  0.727273  0.400000                               57.03   \n",
       "...        ...       ...       ...                                 ...   \n",
       "274683  274683  0.772727  0.800000                              111.01   \n",
       "247787  247787  0.727273  0.500000                              508.53   \n",
       "359644  359644  1.000000  0.133333                              315.28   \n",
       "77978    77978  0.363636  0.366667                               56.95   \n",
       "59950    59950  0.318182  0.433333                              313.57   \n",
       "\n",
       "        nmme0-tmp2m-34w__cancm30  nmme0-tmp2m-34w__cancm40  \\\n",
       "232387                     14.63                     17.29   \n",
       "278778                     11.37                     11.85   \n",
       "348195                      2.85                      6.07   \n",
       "341086                      4.78                      7.90   \n",
       "245447                     -7.91                     -4.59   \n",
       "...                          ...                       ...   \n",
       "274683                     -0.59                     -1.36   \n",
       "247787                     22.07                     24.30   \n",
       "359644                     15.15                     17.45   \n",
       "77978                       2.04                      5.37   \n",
       "59950                      27.62                     29.09   \n",
       "\n",
       "        nmme0-tmp2m-34w__ccsm30  nmme0-tmp2m-34w__ccsm40  \\\n",
       "232387                    16.47                    14.56   \n",
       "278778                    11.03                    11.21   \n",
       "348195                     2.62                     6.55   \n",
       "341086                     6.11                     6.81   \n",
       "245447                    -6.91                    -6.72   \n",
       "...                         ...                      ...   \n",
       "274683                    -3.41                    -2.42   \n",
       "247787                    19.89                    20.49   \n",
       "359644                    12.96                    15.20   \n",
       "77978                      5.04                     4.61   \n",
       "59950                     28.63                    25.41   \n",
       "\n",
       "        nmme0-tmp2m-34w__cfsv20  nmme0-tmp2m-34w__gfdlflora0  ...  \\\n",
       "232387                    14.64                        18.13  ...   \n",
       "278778                    12.34                        10.56  ...   \n",
       "348195                     7.24                         6.18  ...   \n",
       "341086                     5.42                         6.31  ...   \n",
       "245447                    -5.98                        -3.04  ...   \n",
       "...                         ...                          ...  ...   \n",
       "274683                    -1.47                        -0.60  ...   \n",
       "247787                    18.54                        19.37  ...   \n",
       "359644                    14.46                        14.68  ...   \n",
       "77978                      3.09                         4.04  ...   \n",
       "59950                     22.49                        25.27  ...   \n",
       "\n",
       "        wind-vwnd-925-2010-13  wind-vwnd-925-2010-14  wind-vwnd-925-2010-15  \\\n",
       "232387                  -9.84                  14.57                   2.38   \n",
       "278778                 -13.31                  24.93                 -11.19   \n",
       "348195                 -26.02                   1.72                  -2.57   \n",
       "341086                   6.40                  47.12                 -38.47   \n",
       "245447                 -13.57                  42.76                   3.71   \n",
       "...                       ...                    ...                    ...   \n",
       "274683                   4.05                  35.70                  30.94   \n",
       "247787                  -6.03                  33.65                 -56.23   \n",
       "359644                   6.68                   7.30                 -33.97   \n",
       "77978                  -13.85                  20.75                   9.01   \n",
       "59950                   45.85                  34.57                  -2.46   \n",
       "\n",
       "        wind-vwnd-925-2010-16  wind-vwnd-925-2010-17  wind-vwnd-925-2010-18  \\\n",
       "232387                 -27.81                 -53.09                  18.53   \n",
       "278778                 -25.75                  -7.63                   9.48   \n",
       "348195                 -26.51                  47.62                 -38.61   \n",
       "341086                   9.61                  46.26                 -35.05   \n",
       "245447                 -37.34                  -4.44                  -9.71   \n",
       "...                       ...                    ...                    ...   \n",
       "274683                 -24.58                  10.69                   3.29   \n",
       "247787                 -34.12                  19.45                  74.22   \n",
       "359644                  10.50                   3.91                  30.85   \n",
       "77978                  -81.74                  -3.60                   2.72   \n",
       "59950                   62.43                 -19.59                 -45.81   \n",
       "\n",
       "        wind-vwnd-925-2010-19  wind-vwnd-925-2010-20  month  year  \n",
       "232387                  43.93                 -16.79      6    16  \n",
       "278778                 -14.57                   5.05      5    15  \n",
       "348195                   4.73                  69.81      4    15  \n",
       "341086                 -12.54                  37.37     11    15  \n",
       "245447                  50.98                   5.56      3    16  \n",
       "...                       ...                    ...    ...   ...  \n",
       "274683                  28.62                  10.27      3    16  \n",
       "247787                 -14.56                 -24.92      8    16  \n",
       "359644                   0.28                 -14.04      8    16  \n",
       "77978                   -6.00                  16.98      1    16  \n",
       "59950                   46.65                   8.39      9    14  \n",
       "\n",
       "[352604 rows x 247 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a49b065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:26.853862Z",
     "iopub.status.busy": "2023-02-22T15:18:26.853188Z",
     "iopub.status.idle": "2023-02-22T15:18:26.901424Z",
     "shell.execute_reply": "2023-02-22T15:18:26.900261Z"
    },
    "papermill": {
     "duration": 0.060197,
     "end_time": "2023-02-22T15:18:26.903769",
     "exception": false,
     "start_time": "2023-02-22T15:18:26.843572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>contest-pevpr-sfc-gauss-14d__pevpr</th>\n",
       "      <th>nmme0-tmp2m-34w__cancm30</th>\n",
       "      <th>nmme0-tmp2m-34w__cancm40</th>\n",
       "      <th>nmme0-tmp2m-34w__ccsm30</th>\n",
       "      <th>nmme0-tmp2m-34w__ccsm40</th>\n",
       "      <th>nmme0-tmp2m-34w__cfsv20</th>\n",
       "      <th>nmme0-tmp2m-34w__gfdlflora0</th>\n",
       "      <th>...</th>\n",
       "      <th>wind-vwnd-925-2010-13</th>\n",
       "      <th>wind-vwnd-925-2010-14</th>\n",
       "      <th>wind-vwnd-925-2010-15</th>\n",
       "      <th>wind-vwnd-925-2010-16</th>\n",
       "      <th>wind-vwnd-925-2010-17</th>\n",
       "      <th>wind-vwnd-925-2010-18</th>\n",
       "      <th>wind-vwnd-925-2010-19</th>\n",
       "      <th>wind-vwnd-925-2010-20</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>339.88</td>\n",
       "      <td>30.88</td>\n",
       "      <td>30.92</td>\n",
       "      <td>29.17</td>\n",
       "      <td>31.02</td>\n",
       "      <td>29.47</td>\n",
       "      <td>30.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.25</td>\n",
       "      <td>40.88</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-24.62</td>\n",
       "      <td>31.05</td>\n",
       "      <td>-23.69</td>\n",
       "      <td>6.27</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>334.63</td>\n",
       "      <td>30.88</td>\n",
       "      <td>30.92</td>\n",
       "      <td>29.17</td>\n",
       "      <td>31.02</td>\n",
       "      <td>29.47</td>\n",
       "      <td>30.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.62</td>\n",
       "      <td>45.37</td>\n",
       "      <td>-5.42</td>\n",
       "      <td>16.97</td>\n",
       "      <td>-23.94</td>\n",
       "      <td>28.84</td>\n",
       "      <td>-20.61</td>\n",
       "      <td>14.16</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>337.83</td>\n",
       "      <td>30.88</td>\n",
       "      <td>30.92</td>\n",
       "      <td>29.17</td>\n",
       "      <td>31.02</td>\n",
       "      <td>29.47</td>\n",
       "      <td>30.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.67</td>\n",
       "      <td>49.76</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>21.44</td>\n",
       "      <td>-19.06</td>\n",
       "      <td>26.85</td>\n",
       "      <td>-16.78</td>\n",
       "      <td>13.42</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>345.81</td>\n",
       "      <td>30.88</td>\n",
       "      <td>30.92</td>\n",
       "      <td>29.17</td>\n",
       "      <td>31.02</td>\n",
       "      <td>29.47</td>\n",
       "      <td>30.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.32</td>\n",
       "      <td>52.62</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>21.65</td>\n",
       "      <td>-23.12</td>\n",
       "      <td>23.70</td>\n",
       "      <td>-18.62</td>\n",
       "      <td>10.69</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>357.39</td>\n",
       "      <td>30.88</td>\n",
       "      <td>30.92</td>\n",
       "      <td>29.17</td>\n",
       "      <td>31.02</td>\n",
       "      <td>29.47</td>\n",
       "      <td>30.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.89</td>\n",
       "      <td>51.23</td>\n",
       "      <td>-7.57</td>\n",
       "      <td>19.86</td>\n",
       "      <td>-30.56</td>\n",
       "      <td>20.66</td>\n",
       "      <td>-25.08</td>\n",
       "      <td>19.64</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31349</th>\n",
       "      <td>407083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>62.72</td>\n",
       "      <td>4.60</td>\n",
       "      <td>8.71</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.08</td>\n",
       "      <td>6.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>...</td>\n",
       "      <td>32.39</td>\n",
       "      <td>38.82</td>\n",
       "      <td>7.42</td>\n",
       "      <td>11.75</td>\n",
       "      <td>-23.62</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-5.94</td>\n",
       "      <td>51.23</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31350</th>\n",
       "      <td>407084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>73.41</td>\n",
       "      <td>4.60</td>\n",
       "      <td>8.71</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.08</td>\n",
       "      <td>6.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>...</td>\n",
       "      <td>26.23</td>\n",
       "      <td>37.64</td>\n",
       "      <td>13.01</td>\n",
       "      <td>17.84</td>\n",
       "      <td>-22.05</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>1.31</td>\n",
       "      <td>51.45</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31351</th>\n",
       "      <td>407085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>70.00</td>\n",
       "      <td>4.60</td>\n",
       "      <td>8.71</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.08</td>\n",
       "      <td>6.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>...</td>\n",
       "      <td>21.06</td>\n",
       "      <td>36.53</td>\n",
       "      <td>14.15</td>\n",
       "      <td>23.12</td>\n",
       "      <td>-25.60</td>\n",
       "      <td>-5.88</td>\n",
       "      <td>9.32</td>\n",
       "      <td>45.32</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31352</th>\n",
       "      <td>407086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>79.81</td>\n",
       "      <td>4.60</td>\n",
       "      <td>8.71</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.08</td>\n",
       "      <td>6.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>...</td>\n",
       "      <td>20.42</td>\n",
       "      <td>36.05</td>\n",
       "      <td>6.38</td>\n",
       "      <td>29.00</td>\n",
       "      <td>-27.06</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>16.06</td>\n",
       "      <td>31.88</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31353</th>\n",
       "      <td>407087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>86.17</td>\n",
       "      <td>4.60</td>\n",
       "      <td>8.71</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.08</td>\n",
       "      <td>6.39</td>\n",
       "      <td>8.42</td>\n",
       "      <td>...</td>\n",
       "      <td>26.17</td>\n",
       "      <td>30.68</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>27.70</td>\n",
       "      <td>-28.75</td>\n",
       "      <td>0.15</td>\n",
       "      <td>16.64</td>\n",
       "      <td>19.27</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31354 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  lat       lon  contest-pevpr-sfc-gauss-14d__pevpr  \\\n",
       "0      375734  0.0  0.833333                              339.88   \n",
       "1      375735  0.0  0.833333                              334.63   \n",
       "2      375736  0.0  0.833333                              337.83   \n",
       "3      375737  0.0  0.833333                              345.81   \n",
       "4      375738  0.0  0.833333                              357.39   \n",
       "...       ...  ...       ...                                 ...   \n",
       "31349  407083  1.0  0.866667                               62.72   \n",
       "31350  407084  1.0  0.866667                               73.41   \n",
       "31351  407085  1.0  0.866667                               70.00   \n",
       "31352  407086  1.0  0.866667                               79.81   \n",
       "31353  407087  1.0  0.866667                               86.17   \n",
       "\n",
       "       nmme0-tmp2m-34w__cancm30  nmme0-tmp2m-34w__cancm40  \\\n",
       "0                         30.88                     30.92   \n",
       "1                         30.88                     30.92   \n",
       "2                         30.88                     30.92   \n",
       "3                         30.88                     30.92   \n",
       "4                         30.88                     30.92   \n",
       "...                         ...                       ...   \n",
       "31349                      4.60                      8.71   \n",
       "31350                      4.60                      8.71   \n",
       "31351                      4.60                      8.71   \n",
       "31352                      4.60                      8.71   \n",
       "31353                      4.60                      8.71   \n",
       "\n",
       "       nmme0-tmp2m-34w__ccsm30  nmme0-tmp2m-34w__ccsm40  \\\n",
       "0                        29.17                    31.02   \n",
       "1                        29.17                    31.02   \n",
       "2                        29.17                    31.02   \n",
       "3                        29.17                    31.02   \n",
       "4                        29.17                    31.02   \n",
       "...                        ...                      ...   \n",
       "31349                     6.05                    10.08   \n",
       "31350                     6.05                    10.08   \n",
       "31351                     6.05                    10.08   \n",
       "31352                     6.05                    10.08   \n",
       "31353                     6.05                    10.08   \n",
       "\n",
       "       nmme0-tmp2m-34w__cfsv20  nmme0-tmp2m-34w__gfdlflora0  ...  \\\n",
       "0                        29.47                        30.93  ...   \n",
       "1                        29.47                        30.93  ...   \n",
       "2                        29.47                        30.93  ...   \n",
       "3                        29.47                        30.93  ...   \n",
       "4                        29.47                        30.93  ...   \n",
       "...                        ...                          ...  ...   \n",
       "31349                     6.39                         8.42  ...   \n",
       "31350                     6.39                         8.42  ...   \n",
       "31351                     6.39                         8.42  ...   \n",
       "31352                     6.39                         8.42  ...   \n",
       "31353                     6.39                         8.42  ...   \n",
       "\n",
       "       wind-vwnd-925-2010-13  wind-vwnd-925-2010-14  wind-vwnd-925-2010-15  \\\n",
       "0                     -29.25                  40.88                  -8.31   \n",
       "1                     -28.62                  45.37                  -5.42   \n",
       "2                     -27.67                  49.76                  -1.31   \n",
       "3                     -19.32                  52.62                  -0.44   \n",
       "4                      -9.89                  51.23                  -7.57   \n",
       "...                      ...                    ...                    ...   \n",
       "31349                  32.39                  38.82                   7.42   \n",
       "31350                  26.23                  37.64                  13.01   \n",
       "31351                  21.06                  36.53                  14.15   \n",
       "31352                  20.42                  36.05                   6.38   \n",
       "31353                  26.17                  30.68                  -3.24   \n",
       "\n",
       "       wind-vwnd-925-2010-16  wind-vwnd-925-2010-17  wind-vwnd-925-2010-18  \\\n",
       "0                      14.91                 -24.62                  31.05   \n",
       "1                      16.97                 -23.94                  28.84   \n",
       "2                      21.44                 -19.06                  26.85   \n",
       "3                      21.65                 -23.12                  23.70   \n",
       "4                      19.86                 -30.56                  20.66   \n",
       "...                      ...                    ...                    ...   \n",
       "31349                  11.75                 -23.62                  -0.24   \n",
       "31350                  17.84                 -22.05                  -3.03   \n",
       "31351                  23.12                 -25.60                  -5.88   \n",
       "31352                  29.00                 -27.06                  -1.42   \n",
       "31353                  27.70                 -28.75                   0.15   \n",
       "\n",
       "       wind-vwnd-925-2010-19  wind-vwnd-925-2010-20  month  year  \n",
       "0                     -23.69                   6.27     11    22  \n",
       "1                     -20.61                  14.16     11    22  \n",
       "2                     -16.78                  13.42     11    22  \n",
       "3                     -18.62                  10.69     11    22  \n",
       "4                     -25.08                  19.64     11    22  \n",
       "...                      ...                    ...    ...   ...  \n",
       "31349                  -5.94                  51.23     12    22  \n",
       "31350                   1.31                  51.45     12    22  \n",
       "31351                   9.32                  45.32     12    22  \n",
       "31352                  16.06                  31.88     12    22  \n",
       "31353                  16.64                  19.27     12    22  \n",
       "\n",
       "[31354 rows x 246 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce2d0368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:26.923344Z",
     "iopub.status.busy": "2023-02-22T15:18:26.922632Z",
     "iopub.status.idle": "2023-02-22T15:18:27.279853Z",
     "shell.execute_reply": "2023-02-22T15:18:27.278983Z"
    },
    "papermill": {
     "duration": 0.369995,
     "end_time": "2023-02-22T15:18:27.282331",
     "exception": false,
     "start_time": "2023-02-22T15:18:26.912336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df=train_df.astype('float')\n",
    "test_df=test_df.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1137a0c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:27.301440Z",
     "iopub.status.busy": "2023-02-22T15:18:27.301028Z",
     "iopub.status.idle": "2023-02-22T15:18:28.045331Z",
     "shell.execute_reply": "2023-02-22T15:18:28.044217Z"
    },
    "papermill": {
     "duration": 0.756887,
     "end_time": "2023-02-22T15:18:28.047850",
     "exception": false,
     "start_time": "2023-02-22T15:18:27.290963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df=train_df['contest-tmp2m-14d__tmp2m']\n",
    "X_train_df=train_df.drop('contest-tmp2m-14d__tmp2m', axis=1)\n",
    "type(y_train_df)\n",
    "y_train_df=y_train_df.to_frame()\n",
    "type(y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10e4e97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:28.067295Z",
     "iopub.status.busy": "2023-02-22T15:18:28.066666Z",
     "iopub.status.idle": "2023-02-22T15:18:29.133921Z",
     "shell.execute_reply": "2023-02-22T15:18:29.132657Z"
    },
    "papermill": {
     "duration": 1.080192,
     "end_time": "2023-02-22T15:18:29.136762",
     "exception": false,
     "start_time": "2023-02-22T15:18:28.056570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_df=normanlize_data(X_train_df,train_df)\n",
    "test_df=normanlize_data(test_df,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1477502b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:29.155992Z",
     "iopub.status.busy": "2023-02-22T15:18:29.155260Z",
     "iopub.status.idle": "2023-02-22T15:18:29.183943Z",
     "shell.execute_reply": "2023-02-22T15:18:29.182373Z"
    },
    "papermill": {
     "duration": 0.040904,
     "end_time": "2023-02-22T15:18:29.186459",
     "exception": false,
     "start_time": "2023-02-22T15:18:29.145555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 352604 entries, 232387 to 59950\n",
      "Columns: 246 entries, index to year\n",
      "dtypes: float64(246)\n",
      "memory usage: 664.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48869f",
   "metadata": {
    "papermill": {
     "duration": 0.00862,
     "end_time": "2023-02-22T15:18:29.204049",
     "exception": false,
     "start_time": "2023-02-22T15:18:29.195429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c65a206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:29.223966Z",
     "iopub.status.busy": "2023-02-22T15:18:29.222836Z",
     "iopub.status.idle": "2023-02-22T15:18:29.436769Z",
     "shell.execute_reply": "2023-02-22T15:18:29.435204Z"
    },
    "papermill": {
     "duration": 0.230148,
     "end_time": "2023-02-22T15:18:29.443126",
     "exception": false,
     "start_time": "2023-02-22T15:18:29.212978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               31616     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 393,857\n",
      "Trainable params: 393,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 15:18:29.254279: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n",
      "2023-02-22 15:18:29.254329: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "#I might need to change the input_dim to give the actual dimentions\n",
    "#Instead of being just 1\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = 246, activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b44b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:29.465980Z",
     "iopub.status.busy": "2023-02-22T15:18:29.465610Z",
     "iopub.status.idle": "2023-02-22T15:18:29.470483Z",
     "shell.execute_reply": "2023-02-22T15:18:29.469451Z"
    },
    "papermill": {
     "duration": 0.019141,
     "end_time": "2023-02-22T15:18:29.472979",
     "exception": false,
     "start_time": "2023-02-22T15:18:29.453838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights--.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6a4f640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T15:18:29.495335Z",
     "iopub.status.busy": "2023-02-22T15:18:29.494922Z",
     "iopub.status.idle": "2023-02-22T16:02:01.499600Z",
     "shell.execute_reply": "2023-02-22T16:02:01.498270Z"
    },
    "papermill": {
     "duration": 2612.019333,
     "end_time": "2023-02-22T16:02:01.502638",
     "exception": false,
     "start_time": "2023-02-22T15:18:29.483305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8812/8816 [============================>.] - ETA: 0s - loss: 1.1297 - mean_absolute_error: 1.1297\n",
      "Epoch 1: val_loss improved from inf to 0.92552, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 1.1296 - mean_absolute_error: 1.1296 - val_loss: 0.9255 - val_mean_absolute_error: 0.9255\n",
      "Epoch 2/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.8447 - mean_absolute_error: 0.8447\n",
      "Epoch 2: val_loss improved from 0.92552 to 0.72034, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 49s 6ms/step - loss: 0.8447 - mean_absolute_error: 0.8447 - val_loss: 0.7203 - val_mean_absolute_error: 0.7203\n",
      "Epoch 3/50\n",
      "8807/8816 [============================>.] - ETA: 0s - loss: 0.7660 - mean_absolute_error: 0.7660\n",
      "Epoch 3: val_loss did not improve from 0.72034\n",
      "8816/8816 [==============================] - 49s 6ms/step - loss: 0.7661 - mean_absolute_error: 0.7661 - val_loss: 0.8695 - val_mean_absolute_error: 0.8695\n",
      "Epoch 4/50\n",
      "8811/8816 [============================>.] - ETA: 0s - loss: 0.7183 - mean_absolute_error: 0.7183\n",
      "Epoch 4: val_loss improved from 0.72034 to 0.64811, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 0.7182 - mean_absolute_error: 0.7182 - val_loss: 0.6481 - val_mean_absolute_error: 0.6481\n",
      "Epoch 5/50\n",
      "8812/8816 [============================>.] - ETA: 0s - loss: 0.6810 - mean_absolute_error: 0.6810\n",
      "Epoch 5: val_loss improved from 0.64811 to 0.63591, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 0.6809 - mean_absolute_error: 0.6809 - val_loss: 0.6359 - val_mean_absolute_error: 0.6359\n",
      "Epoch 6/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.6533 - mean_absolute_error: 0.6533\n",
      "Epoch 6: val_loss did not improve from 0.63591\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.6533 - mean_absolute_error: 0.6533 - val_loss: 0.7005 - val_mean_absolute_error: 0.7005\n",
      "Epoch 7/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.6314 - mean_absolute_error: 0.6314\n",
      "Epoch 7: val_loss improved from 0.63591 to 0.61369, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 49s 6ms/step - loss: 0.6314 - mean_absolute_error: 0.6314 - val_loss: 0.6137 - val_mean_absolute_error: 0.6137\n",
      "Epoch 8/50\n",
      "8814/8816 [============================>.] - ETA: 0s - loss: 0.6115 - mean_absolute_error: 0.6115\n",
      "Epoch 8: val_loss improved from 0.61369 to 0.60131, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.6114 - mean_absolute_error: 0.6114 - val_loss: 0.6013 - val_mean_absolute_error: 0.6013\n",
      "Epoch 9/50\n",
      "8810/8816 [============================>.] - ETA: 0s - loss: 0.5976 - mean_absolute_error: 0.5976\n",
      "Epoch 9: val_loss improved from 0.60131 to 0.56997, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.5976 - mean_absolute_error: 0.5976 - val_loss: 0.5700 - val_mean_absolute_error: 0.5700\n",
      "Epoch 10/50\n",
      "8808/8816 [============================>.] - ETA: 0s - loss: 0.5814 - mean_absolute_error: 0.5814\n",
      "Epoch 10: val_loss improved from 0.56997 to 0.55614, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 0.5814 - mean_absolute_error: 0.5814 - val_loss: 0.5561 - val_mean_absolute_error: 0.5561\n",
      "Epoch 11/50\n",
      "8808/8816 [============================>.] - ETA: 0s - loss: 0.5686 - mean_absolute_error: 0.5686\n",
      "Epoch 11: val_loss improved from 0.55614 to 0.54782, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.5686 - mean_absolute_error: 0.5686 - val_loss: 0.5478 - val_mean_absolute_error: 0.5478\n",
      "Epoch 12/50\n",
      "8809/8816 [============================>.] - ETA: 0s - loss: 0.5582 - mean_absolute_error: 0.5582\n",
      "Epoch 12: val_loss did not improve from 0.54782\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.5582 - mean_absolute_error: 0.5582 - val_loss: 0.5558 - val_mean_absolute_error: 0.5558\n",
      "Epoch 13/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.5482 - mean_absolute_error: 0.5482\n",
      "Epoch 13: val_loss improved from 0.54782 to 0.54415, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 54s 6ms/step - loss: 0.5483 - mean_absolute_error: 0.5483 - val_loss: 0.5442 - val_mean_absolute_error: 0.5442\n",
      "Epoch 14/50\n",
      "8814/8816 [============================>.] - ETA: 0s - loss: 0.5411 - mean_absolute_error: 0.5411\n",
      "Epoch 14: val_loss did not improve from 0.54415\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.5411 - mean_absolute_error: 0.5411 - val_loss: 0.6099 - val_mean_absolute_error: 0.6099\n",
      "Epoch 15/50\n",
      "8814/8816 [============================>.] - ETA: 0s - loss: 0.5327 - mean_absolute_error: 0.5327\n",
      "Epoch 15: val_loss improved from 0.54415 to 0.50524, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.5327 - mean_absolute_error: 0.5327 - val_loss: 0.5052 - val_mean_absolute_error: 0.5052\n",
      "Epoch 16/50\n",
      "8808/8816 [============================>.] - ETA: 0s - loss: 0.5270 - mean_absolute_error: 0.5270\n",
      "Epoch 16: val_loss did not improve from 0.50524\n",
      "8816/8816 [==============================] - 54s 6ms/step - loss: 0.5270 - mean_absolute_error: 0.5270 - val_loss: 0.5070 - val_mean_absolute_error: 0.5070\n",
      "Epoch 17/50\n",
      "8814/8816 [============================>.] - ETA: 0s - loss: 0.5173 - mean_absolute_error: 0.5173\n",
      "Epoch 17: val_loss did not improve from 0.50524\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.5173 - mean_absolute_error: 0.5173 - val_loss: 0.5100 - val_mean_absolute_error: 0.5100\n",
      "Epoch 18/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.5137 - mean_absolute_error: 0.5137\n",
      "Epoch 18: val_loss did not improve from 0.50524\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.5137 - mean_absolute_error: 0.5137 - val_loss: 0.5064 - val_mean_absolute_error: 0.5064\n",
      "Epoch 19/50\n",
      "8816/8816 [==============================] - ETA: 0s - loss: 0.5066 - mean_absolute_error: 0.5066\n",
      "Epoch 19: val_loss did not improve from 0.50524\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.5066 - mean_absolute_error: 0.5066 - val_loss: 0.5063 - val_mean_absolute_error: 0.5063\n",
      "Epoch 20/50\n",
      "8811/8816 [============================>.] - ETA: 0s - loss: 0.5000 - mean_absolute_error: 0.5000\n",
      "Epoch 20: val_loss improved from 0.50524 to 0.48526, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.5000 - mean_absolute_error: 0.5000 - val_loss: 0.4853 - val_mean_absolute_error: 0.4853\n",
      "Epoch 21/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4943 - mean_absolute_error: 0.4943\n",
      "Epoch 21: val_loss did not improve from 0.48526\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.4944 - mean_absolute_error: 0.4944 - val_loss: 0.5677 - val_mean_absolute_error: 0.5677\n",
      "Epoch 22/50\n",
      "8807/8816 [============================>.] - ETA: 0s - loss: 0.4901 - mean_absolute_error: 0.4901\n",
      "Epoch 22: val_loss did not improve from 0.48526\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.4901 - mean_absolute_error: 0.4901 - val_loss: 0.6524 - val_mean_absolute_error: 0.6524\n",
      "Epoch 23/50\n",
      "8810/8816 [============================>.] - ETA: 0s - loss: 0.4855 - mean_absolute_error: 0.4855\n",
      "Epoch 23: val_loss did not improve from 0.48526\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.4855 - mean_absolute_error: 0.4855 - val_loss: 0.5602 - val_mean_absolute_error: 0.5602\n",
      "Epoch 24/50\n",
      "8814/8816 [============================>.] - ETA: 0s - loss: 0.4813 - mean_absolute_error: 0.4813\n",
      "Epoch 24: val_loss improved from 0.48526 to 0.46461, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 54s 6ms/step - loss: 0.4813 - mean_absolute_error: 0.4813 - val_loss: 0.4646 - val_mean_absolute_error: 0.4646\n",
      "Epoch 25/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4755 - mean_absolute_error: 0.4755\n",
      "Epoch 25: val_loss did not improve from 0.46461\n",
      "8816/8816 [==============================] - 56s 6ms/step - loss: 0.4755 - mean_absolute_error: 0.4755 - val_loss: 0.5488 - val_mean_absolute_error: 0.5488\n",
      "Epoch 26/50\n",
      "8815/8816 [============================>.] - ETA: 0s - loss: 0.4732 - mean_absolute_error: 0.4732\n",
      "Epoch 26: val_loss improved from 0.46461 to 0.45582, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.4732 - mean_absolute_error: 0.4732 - val_loss: 0.4558 - val_mean_absolute_error: 0.4558\n",
      "Epoch 27/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4693 - mean_absolute_error: 0.4693\n",
      "Epoch 27: val_loss did not improve from 0.45582\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.4693 - mean_absolute_error: 0.4693 - val_loss: 0.4725 - val_mean_absolute_error: 0.4725\n",
      "Epoch 28/50\n",
      "8809/8816 [============================>.] - ETA: 0s - loss: 0.4665 - mean_absolute_error: 0.4665\n",
      "Epoch 28: val_loss improved from 0.45582 to 0.45045, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 0.4665 - mean_absolute_error: 0.4665 - val_loss: 0.4505 - val_mean_absolute_error: 0.4505\n",
      "Epoch 29/50\n",
      "8809/8816 [============================>.] - ETA: 0s - loss: 0.4626 - mean_absolute_error: 0.4626\n",
      "Epoch 29: val_loss improved from 0.45045 to 0.44482, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.4626 - mean_absolute_error: 0.4626 - val_loss: 0.4448 - val_mean_absolute_error: 0.4448\n",
      "Epoch 30/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4600 - mean_absolute_error: 0.4600\n",
      "Epoch 30: val_loss did not improve from 0.44482\n",
      "8816/8816 [==============================] - 54s 6ms/step - loss: 0.4600 - mean_absolute_error: 0.4600 - val_loss: 0.4708 - val_mean_absolute_error: 0.4708\n",
      "Epoch 31/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4560 - mean_absolute_error: 0.4560\n",
      "Epoch 31: val_loss did not improve from 0.44482\n",
      "8816/8816 [==============================] - 54s 6ms/step - loss: 0.4560 - mean_absolute_error: 0.4560 - val_loss: 0.5131 - val_mean_absolute_error: 0.5131\n",
      "Epoch 32/50\n",
      "8808/8816 [============================>.] - ETA: 0s - loss: 0.4541 - mean_absolute_error: 0.4541\n",
      "Epoch 32: val_loss did not improve from 0.44482\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.4541 - mean_absolute_error: 0.4541 - val_loss: 0.4496 - val_mean_absolute_error: 0.4496\n",
      "Epoch 33/50\n",
      "8809/8816 [============================>.] - ETA: 0s - loss: 0.4485 - mean_absolute_error: 0.4485\n",
      "Epoch 33: val_loss did not improve from 0.44482\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.4485 - mean_absolute_error: 0.4485 - val_loss: 0.4867 - val_mean_absolute_error: 0.4867\n",
      "Epoch 34/50\n",
      "8812/8816 [============================>.] - ETA: 0s - loss: 0.4461 - mean_absolute_error: 0.4461\n",
      "Epoch 34: val_loss did not improve from 0.44482\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.4460 - mean_absolute_error: 0.4460 - val_loss: 0.4735 - val_mean_absolute_error: 0.4735\n",
      "Epoch 35/50\n",
      "8812/8816 [============================>.] - ETA: 0s - loss: 0.4454 - mean_absolute_error: 0.4454\n",
      "Epoch 35: val_loss did not improve from 0.44482\n",
      "8816/8816 [==============================] - 54s 6ms/step - loss: 0.4453 - mean_absolute_error: 0.4453 - val_loss: 0.4598 - val_mean_absolute_error: 0.4598\n",
      "Epoch 36/50\n",
      "8808/8816 [============================>.] - ETA: 0s - loss: 0.4412 - mean_absolute_error: 0.4412\n",
      "Epoch 36: val_loss did not improve from 0.44482\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.4412 - mean_absolute_error: 0.4412 - val_loss: 0.4752 - val_mean_absolute_error: 0.4752\n",
      "Epoch 37/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4388 - mean_absolute_error: 0.4388\n",
      "Epoch 37: val_loss improved from 0.44482 to 0.43514, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.4388 - mean_absolute_error: 0.4388 - val_loss: 0.4351 - val_mean_absolute_error: 0.4351\n",
      "Epoch 38/50\n",
      "8815/8816 [============================>.] - ETA: 0s - loss: 0.4355 - mean_absolute_error: 0.4355\n",
      "Epoch 38: val_loss did not improve from 0.43514\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.4355 - mean_absolute_error: 0.4355 - val_loss: 0.4882 - val_mean_absolute_error: 0.4882\n",
      "Epoch 39/50\n",
      "8816/8816 [==============================] - ETA: 0s - loss: 0.4335 - mean_absolute_error: 0.4335\n",
      "Epoch 39: val_loss improved from 0.43514 to 0.43212, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 53s 6ms/step - loss: 0.4335 - mean_absolute_error: 0.4335 - val_loss: 0.4321 - val_mean_absolute_error: 0.4321\n",
      "Epoch 40/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4302 - mean_absolute_error: 0.4302\n",
      "Epoch 40: val_loss did not improve from 0.43212\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 0.4302 - mean_absolute_error: 0.4302 - val_loss: 0.4542 - val_mean_absolute_error: 0.4542\n",
      "Epoch 41/50\n",
      "8814/8816 [============================>.] - ETA: 0s - loss: 0.4279 - mean_absolute_error: 0.4279\n",
      "Epoch 41: val_loss did not improve from 0.43212\n",
      "8816/8816 [==============================] - 59s 7ms/step - loss: 0.4279 - mean_absolute_error: 0.4279 - val_loss: 0.4707 - val_mean_absolute_error: 0.4707\n",
      "Epoch 42/50\n",
      "8812/8816 [============================>.] - ETA: 0s - loss: 0.4260 - mean_absolute_error: 0.4260\n",
      "Epoch 42: val_loss did not improve from 0.43212\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.4260 - mean_absolute_error: 0.4260 - val_loss: 0.4334 - val_mean_absolute_error: 0.4334\n",
      "Epoch 43/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4245 - mean_absolute_error: 0.4245\n",
      "Epoch 43: val_loss did not improve from 0.43212\n",
      "8816/8816 [==============================] - 55s 6ms/step - loss: 0.4246 - mean_absolute_error: 0.4246 - val_loss: 0.4557 - val_mean_absolute_error: 0.4557\n",
      "Epoch 44/50\n",
      "8810/8816 [============================>.] - ETA: 0s - loss: 0.4224 - mean_absolute_error: 0.4224\n",
      "Epoch 44: val_loss did not improve from 0.43212\n",
      "8816/8816 [==============================] - 52s 6ms/step - loss: 0.4224 - mean_absolute_error: 0.4224 - val_loss: 0.4692 - val_mean_absolute_error: 0.4692\n",
      "Epoch 45/50\n",
      "8807/8816 [============================>.] - ETA: 0s - loss: 0.4193 - mean_absolute_error: 0.4193\n",
      "Epoch 45: val_loss improved from 0.43212 to 0.41292, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.4194 - mean_absolute_error: 0.4194 - val_loss: 0.4129 - val_mean_absolute_error: 0.4129\n",
      "Epoch 46/50\n",
      "8813/8816 [============================>.] - ETA: 0s - loss: 0.4189 - mean_absolute_error: 0.4189\n",
      "Epoch 46: val_loss did not improve from 0.41292\n",
      "8816/8816 [==============================] - 51s 6ms/step - loss: 0.4189 - mean_absolute_error: 0.4189 - val_loss: 0.4152 - val_mean_absolute_error: 0.4152\n",
      "Epoch 47/50\n",
      "8812/8816 [============================>.] - ETA: 0s - loss: 0.4158 - mean_absolute_error: 0.4158\n",
      "Epoch 47: val_loss did not improve from 0.41292\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 0.4158 - mean_absolute_error: 0.4158 - val_loss: 0.4843 - val_mean_absolute_error: 0.4843\n",
      "Epoch 48/50\n",
      "8808/8816 [============================>.] - ETA: 0s - loss: 0.4150 - mean_absolute_error: 0.4150\n",
      "Epoch 48: val_loss improved from 0.41292 to 0.40917, saving model to Weights--.hdf5\n",
      "8816/8816 [==============================] - 50s 6ms/step - loss: 0.4150 - mean_absolute_error: 0.4150 - val_loss: 0.4092 - val_mean_absolute_error: 0.4092\n",
      "Epoch 49/50\n",
      "8808/8816 [============================>.] - ETA: 0s - loss: 0.4127 - mean_absolute_error: 0.4127\n",
      "Epoch 49: val_loss did not improve from 0.40917\n",
      "8816/8816 [==============================] - 57s 6ms/step - loss: 0.4127 - mean_absolute_error: 0.4127 - val_loss: 0.4337 - val_mean_absolute_error: 0.4337\n",
      "Epoch 50/50\n",
      "8809/8816 [============================>.] - ETA: 0s - loss: 0.4109 - mean_absolute_error: 0.4109\n",
      "Epoch 50: val_loss did not improve from 0.40917\n",
      "8816/8816 [==============================] - 54s 6ms/step - loss: 0.4109 - mean_absolute_error: 0.4109 - val_loss: 0.4220 - val_mean_absolute_error: 0.4220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc51a1af10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(X_train_df, y_train_df, epochs=50, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa19a407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T16:02:07.660543Z",
     "iopub.status.busy": "2023-02-22T16:02:07.660103Z",
     "iopub.status.idle": "2023-02-22T16:02:07.698102Z",
     "shell.execute_reply": "2023-02-22T16:02:07.696789Z"
    },
    "papermill": {
     "duration": 3.149309,
     "end_time": "2023-02-22T16:02:07.701091",
     "exception": false,
     "start_time": "2023-02-22T16:02:04.551782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load wights file of the best model :\n",
    "wights_file = f'Weights--.hdf5'  # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a72b621f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T16:02:13.652733Z",
     "iopub.status.busy": "2023-02-22T16:02:13.652344Z",
     "iopub.status.idle": "2023-02-22T16:02:19.124930Z",
     "shell.execute_reply": "2023-02-22T16:02:19.123725Z"
    },
    "papermill": {
     "duration": 8.44766,
     "end_time": "2023-02-22T16:02:19.127955",
     "exception": false,
     "start_time": "2023-02-22T16:02:10.680295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980/980 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = NN_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e0282",
   "metadata": {
    "papermill": {
     "duration": 2.996289,
     "end_time": "2023-02-22T16:02:25.154721",
     "exception": false,
     "start_time": "2023-02-22T16:02:22.158432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving Dataset in correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47db3ec0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T16:02:31.143898Z",
     "iopub.status.busy": "2023-02-22T16:02:31.143515Z",
     "iopub.status.idle": "2023-02-22T16:02:31.149856Z",
     "shell.execute_reply": "2023-02-22T16:02:31.149055Z"
    },
    "papermill": {
     "duration": 3.037368,
     "end_time": "2023-02-22T16:02:31.151817",
     "exception": false,
     "start_time": "2023-02-22T16:02:28.114449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.31366   ],\n",
       "       [26.319752  ],\n",
       "       [26.204178  ],\n",
       "       ...,\n",
       "       [ 0.23083961],\n",
       "       [ 0.62028813],\n",
       "       [ 0.20060784]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8943b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T16:02:37.183620Z",
     "iopub.status.busy": "2023-02-22T16:02:37.182840Z",
     "iopub.status.idle": "2023-02-22T16:02:37.188620Z",
     "shell.execute_reply": "2023-02-22T16:02:37.187674Z"
    },
    "papermill": {
     "duration": 2.973271,
     "end_time": "2023-02-22T16:02:37.191074",
     "exception": false,
     "start_time": "2023-02-22T16:02:34.217803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final=pd.DataFrame(predictions,columns=['contest-tmp2m-14d__tmp2m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c9150a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T16:02:43.253118Z",
     "iopub.status.busy": "2023-02-22T16:02:43.252736Z",
     "iopub.status.idle": "2023-02-22T16:02:51.265041Z",
     "shell.execute_reply": "2023-02-22T16:02:51.263750Z"
    },
    "papermill": {
     "duration": 11.065631,
     "end_time": "2023-02-22T16:02:51.267711",
     "exception": false,
     "start_time": "2023-02-22T16:02:40.202080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contest-tmp2m-14d__tmp2m</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.313660</td>\n",
       "      <td>375734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.319752</td>\n",
       "      <td>375735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.204178</td>\n",
       "      <td>375736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.221939</td>\n",
       "      <td>375737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.245932</td>\n",
       "      <td>375738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31349</th>\n",
       "      <td>2.746720</td>\n",
       "      <td>407083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31350</th>\n",
       "      <td>2.198187</td>\n",
       "      <td>407084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31351</th>\n",
       "      <td>0.230840</td>\n",
       "      <td>407085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31352</th>\n",
       "      <td>0.620288</td>\n",
       "      <td>407086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31353</th>\n",
       "      <td>0.200608</td>\n",
       "      <td>407087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       contest-tmp2m-14d__tmp2m   index\n",
       "0                     26.313660  375734\n",
       "1                     26.319752  375735\n",
       "2                     26.204178  375736\n",
       "3                     26.221939  375737\n",
       "4                     26.245932  375738\n",
       "...                         ...     ...\n",
       "31349                  2.746720  407083\n",
       "31350                  2.198187  407084\n",
       "31351                  0.230840  407085\n",
       "31352                  0.620288  407086\n",
       "31353                  0.200608  407087\n",
       "\n",
       "[31354 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=375734\n",
    "final['index']=0\n",
    "while i<407088:\n",
    "    final['index'][i-375734]=i\n",
    "    i+=1\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47710a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-22T16:02:57.199700Z",
     "iopub.status.busy": "2023-02-22T16:02:57.198886Z",
     "iopub.status.idle": "2023-02-22T16:02:57.267475Z",
     "shell.execute_reply": "2023-02-22T16:02:57.266238Z"
    },
    "papermill": {
     "duration": 3.040628,
     "end_time": "2023-02-22T16:02:57.270490",
     "exception": false,
     "start_time": "2023-02-22T16:02:54.229862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final.to_csv('/kaggle/working/wetherprediction.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2723.744819,
   "end_time": "2023-02-22T16:03:03.117871",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-22T15:17:39.373052",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
